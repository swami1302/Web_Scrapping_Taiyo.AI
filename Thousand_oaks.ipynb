{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxCe6oDK4Twc+ZwhoG9X24"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-j_pA7JGqLB","executionInfo":{"status":"ok","timestamp":1714319789240,"user_tz":-330,"elapsed":1000,"user":{"displayName":"Sukant Sakthivel","userId":"08416366476321777514"}},"outputId":"62c3b18a-eca5-4ee6-f383-c0b3df816232"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data successfully scraped and saved to thousand_oaks.csv\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","# Define the URL\n","url = 'https://www.toaks.org/departments/public-works/construction'\n","\n","try:\n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","    response.raise_for_status()  # Raise an exception for unsuccessful HTTP response codes\n","\n","    # Parse the HTML content of the webpage\n","    soup = BeautifulSoup(response.text, 'html.parser')\n","\n","    # Find all elements with the specified classes\n","    first_elements = soup.find_all(class_='content_area normal_content_area clearfix')\n","\n","\n","    # Extract the content from all elements with the specified classes\n","    first_content_list = [element.text.strip() for element in first_elements]\n","\n","\n","    # Open a CSV file for writing\n","    with open('./thousand_oaks', 'w', newline='', encoding='utf-8') as csvfile:\n","        # Create a CSV writer object\n","        writer = csv.writer(csvfile)\n","\n","        # Write headers to the CSV file\n","        writer.writerow(['Content from content_area normal_content_area clearfix'])  # Replace 'YourClassHere' with the third class name\n","\n","        # Write the content to the CSV file\n","        max_rows = len(first_content_list)\n","        for i in range(max_rows):\n","            first_content = first_content_list[i] if i < len(first_content_list) else ''\n","\n","            writer.writerow([first_content])\n","\n","    print('Data successfully scraped and saved to thousand_oaks.csv')\n","\n","except requests.exceptions.RequestException as e:\n","    print(f\"Error: {e}\")"]}]}